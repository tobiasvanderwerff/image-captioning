# image-captioning
This repository contains a PyTorch implementation of a deep learning based image-captioning system, inspired by the 2015 paper from Xu et al. [1]. The system uses visual features from a CNN in combination with a LSTM language decoder and an attention mechanism to predict image captions.

## Installation
Download the necessary packages, e.g. using pip:  

```
pip install -r requirements.txt
```

## References
[1] Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Rus-lan Salakhudinov, Rich Zemel, and Yoshua Bengio. Show, attend and tell: Neural  image  caption  generation  with  visual  attention.   In *International conference on machine learning*, pages 2048â€“2057. PMLR, 2015.
